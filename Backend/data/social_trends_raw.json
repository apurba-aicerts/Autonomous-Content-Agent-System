[
  {
    "id": "1oyrqvp",
    "title": "These agents formed a temporary alliance‚Ä¶ we‚Äôre trying to figure out why.",
    "selftext": "Two agents teamed up against a third but only after the evidence got extremely one-sided.\nIt‚Äôs like a natural consensus mechanism kicked in.\n\nA few people in the free beta replicated it, so now we‚Äôre comparing runs.\nIf stuff like this interests you, the beta‚Äôs open and we could use more testers.",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 1,
    "created_utc": "2025-11-16 23:04:29",
    "subreddit": "learnmachinelearning",
    "url": "https://www.reddit.com/r/learnmachinelearning/comments/1oyrqvp/these_agents_formed_a_temporary_alliance_were/"
  },
  {
    "id": "1oyqwve",
    "title": "üöÄ Project Showcase Day",
    "selftext": "Welcome to Project Showcase Day! This is a weekly thread where community members can share and discuss personal projects of any size or complexity.\n\nWhether you've built a small script, a web application, a game, or anything in between, we encourage you to:\n\n* Share what you've created\n* Explain the technologies/concepts used\n* Discuss challenges you faced and how you overcame them\n* Ask for specific feedback or suggestions\n\nProjects at all stages are welcome - from works in progress to completed builds. This is a supportive space to celebrate your work and learn from each other.\n\nShare your creations in the comments below!",
    "score": 1,
    "ups": 1,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 22:32:07",
    "subreddit": "learnmachinelearning",
    "url": "https://www.reddit.com/r/learnmachinelearning/comments/1oyqwve/project_showcase_day/"
  },
  {
    "id": "1oypqr2",
    "title": "Built an open-source lightweight MLOps tool ‚Äî looking for feedback",
    "selftext": "I built *Skyulf*, an open-source MLOps app for visually orchestrating data pipelines and model training workflows.\n\nIt uses:\n\n* **React Flow** for pipeline UI\n* **Python** backend\n\nI‚Äôm trying to keep it lightweight and beginner-friendly compared tools. No code needed.\n\nI‚Äôd love feedback from people who work with ML pipelines:\n\n* What features matter most to you?\n* Is visual pipeline building useful?\n* What would you expect from a minimal MLOps system?\n\nRepo: [https://github.com/flyingriverhorse/Skyulf](https://github.com/flyingriverhorse/Skyulf)\n\nAny suggestions or criticism is extremely welcome.",
    "score": 1,
    "ups": 1,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 21:46:08",
    "subreddit": "learnmachinelearning",
    "url": "https://www.reddit.com/r/learnmachinelearning/comments/1oypqr2/built_an_opensource_lightweight_mlops_tool/"
  },
  {
    "id": "1oyowqh",
    "title": "is a master‚Äôs worth it for my AI career goals? need help deciding next steps",
    "selftext": "Hi everyone. I‚Äôm a 3rd-year undergrad from a tier-2 uni in India and I‚Äôm planning to apply for Master‚Äôs programs in AI/CS next year. I‚Äôm attaching my resume and would really appreciate some guidance because I‚Äôm honestly confused about where I stand.\n\nI‚Äôve tried to build a strong profile through research-style engineering work: diffusion models from scratch, GPT from scratch, VLM pipelines, RAG systems, etc. I‚Äôve interned at Samsung Research, a startup in NYC, and collaborated with a PhD student at Princeton. Most of my work is engineering, but I don‚Äôt have major research publications yet, and I constantly feel unsure about my actual capability compared to others applying to top programs.\n\nFor context, my long-term goal is to work as a research engineer / applied scientist. Specifically, I want to work on taking research notebooks from big brained PhDs and turning them into robust, production-ready systems. That means I need strong core AI knowledge, solid SWE fundamentals, and the ability to productionize models and build infra. I don‚Äôt think I‚Äôll be able to pursue a PhD after a Master‚Äôs.\n\nI want to understand a few things:\n\n1. **Is doing a Master‚Äôs even worth it for the kind of career I‚Äôm aiming at?** And if yes, would an online Master‚Äôs while working full-time be a reasonable path?\n2. **Does not having a Master‚Äôs noticeably hurt opportunities for research-engineering-style roles?**\n3. **What are my realistic chances for good AI-focused MS programs in the US/EU/Canada/MBZUAI?**\n4. **Am I strong enough to target a research internship under a top professor?** I genuinely don‚Äôt know where I stand relative to the competition.\n5. **What should I prioritize over the next year?** More research? Competitions? Open-source? Larger projects? Something else?\n6. **What‚Äôs the best path forward to give myself a solid chance next year?**\n\n[resume](https://preview.redd.it/7rgrf8z13n1g1.png?width=981&format=png&auto=webp&s=080325d69f842ca7d020a3f49d9d93415ef7e43a)\n\nI‚Äôm willing to work very hard. I just feel lost about direction. Any honest feedback or advice would help a lot. Thanks.  \n",
    "score": 1,
    "ups": 1,
    "downs": 0,
    "comments": 5,
    "created_utc": "2025-11-16 21:13:24",
    "subreddit": "learnmachinelearning",
    "url": "https://www.reddit.com/r/learnmachinelearning/comments/1oyowqh/is_a_masters_worth_it_for_my_ai_career_goals_need/"
  },
  {
    "id": "1oyosku",
    "title": "Attention Is All You Need",
    "selftext": "Hi everyone!\n\nI'm in the process of learning AI and I've been using Google's NotebookLM to help me break down complex topics. I fed it the \"Attention Is All You Need\" paper and some notes, and I was really impressed when it generated this \"Video Overview\" to help me study.\n\nThe video itself (which was made by the tool) covers:\n\n* The \"Sequential Bottleneck\" problem (why we needed a change from RNNs).\n* A simple explanation of Self-Attention (Query, Key, Value).\n* How Positional Encoding solves the \"word order\" problem.\n\nI thought the output was pretty cool and might be helpful for other learners, so I'm sharing it. This is the first video for my new \"The AI Lab Journal\" channel. I'd love to hear what you all think about this as a learning method!\n\n[Attention Is All You Need](https://youtu.be/6lZNBM5Ee0I)\n\n",
    "score": 4,
    "ups": 4,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 21:08:45",
    "subreddit": "learnmachinelearning",
    "url": "https://www.reddit.com/r/learnmachinelearning/comments/1oyosku/attention_is_all_you_need/"
  },
  {
    "id": "1oyop48",
    "title": "international internship goal",
    "selftext": "hi Reddit,\nI am currently enrolled in a computer science course in a university in India. my uni isn't very big it's more like a community college ig. my cgpa isnt too good it's a little below 7 out of 10, i am working on pushing it up to atleast 8. I also have a back/failed subject in dsa in my 2nd semester. although I think because of my slacking in one field I think I have done better than my peers in the other. I have worked on a geo mapping python code where I would just type in a location and it would locate it on a map(not world changing or smthn ik) and a stock market trend predictor where my ml code would just try to predict if the market would go up the next day or down(sounds revolutionary but it was really just a basic ml project with the code's prediction being right about 50% of the times). I like ml and python. I am in my 3rd semester, starting 4th. I wish to get an international internship during my 4th year as well as the summer of 2027 in the financial field. what should I do and what project should i work on to achieve this goal. ",
    "score": 1,
    "ups": 1,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 21:04:49",
    "subreddit": "learnmachinelearning",
    "url": "https://www.reddit.com/r/learnmachinelearning/comments/1oyop48/international_internship_goal/"
  },
  {
    "id": "1oyoj7r",
    "title": "Feature matching and homography for automatic image annotation pipeline",
    "selftext": "This tutorial shows how to extract SIFT keypoints, match features across images, and use homography to generate automatic bounding-box annotations. With the optimal parameters tuning, it generates 70 correct annotations out of 72 images\n\nNotebook:¬†[https://github.com/paulinamoskwa/notebooks](https://github.com/paulinamoskwa/notebooks)\n\n([or try it on Colab](https://colab.research.google.com/github/paulinamoskwa/notebooks/blob/main/notebooks/image_annotation_with_feature_matching_and_homography.ipynb))",
    "score": 1,
    "ups": 1,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 20:58:01",
    "subreddit": "learnmachinelearning",
    "url": "https://www.reddit.com/r/learnmachinelearning/comments/1oyoj7r/feature_matching_and_homography_for_automatic/"
  },
  {
    "id": "1oylk3g",
    "title": "Interest in Sri Lankan Sinhala & Tamil AI Language Models?",
    "selftext": "We are research team exploring the idea of developing¬†**Sri Lankan-focused AI language models**¬†for¬†**Sinhala and Tamil**.\n\nOur goal is to build LLMs that understand:\n\nLocal Sinhala and Tamil dialects\n\nCultural context\n\nRegional slang\n\nSri Lankan names, places, and daily usage\n\nBefore we go deeper into the project, we want to gather some community insights:\n\n1. **Would you be interested in using a Sinhala or Tamil AI assistant?**\n2. **What features would be most useful to you?**\n3. **What problems do you currently face when using AI tools in Sinhala or Tamil?**\n4. **Do you think such localized models are needed in Sri Lanka? Why or why not?**",
    "score": 1,
    "ups": 1,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 18:50:09",
    "subreddit": "learnmachinelearning",
    "url": "https://www.reddit.com/r/learnmachinelearning/comments/1oylk3g/interest_in_sri_lankan_sinhala_tamil_ai_language/"
  },
  {
    "id": "1oykf7e",
    "title": "üì¢ Looking to Connect with Data Scientists for Collaboration, Kaggle, and Skill Growth",
    "selftext": "Hey everyone! üëã\n\nI‚Äôm a data scientist and I‚Äôm looking to connect with others in the field‚Äîwhether you're a beginner, intermediate, or advanced. My goal is to form a small group or team where we can:\n\n* Collaborate on Kaggle competitions üèÜ\n* Work on portfolio projects together\n* Share knowledge, resources, and tips\n* Practice teamwork like real-world ML teams\n* Hold each other accountable and motivated\n* Possibly build something meaningful over time\n\nI‚Äôm especially interested in machine learning, MLOps, model deployment, and data engineering pipelines‚Äîbut I‚Äôm open to any area of data science!\n\nIf you‚Äôre interested in:  \n‚úî Learning together  \n‚úî Working on real problems  \n‚úî Growing your skills through collaboration  \n‚úî Building a serious portfolio  \n‚úî Connecting with like-minded people\n\nThen feel free to comment or DM me! Let‚Äôs build something awesome together üöÄ",
    "score": 6,
    "ups": 6,
    "downs": 0,
    "comments": 1,
    "created_utc": "2025-11-16 17:53:52",
    "subreddit": "learnmachinelearning",
    "url": "https://www.reddit.com/r/learnmachinelearning/comments/1oykf7e/looking_to_connect_with_data_scientists_for/"
  },
  {
    "id": "1oyjz9l",
    "title": "I am looking out for a cofounder who knows to handle data and ML",
    "selftext": "I am an aerospace engineering undergrad and as the title says I am looking out for a cofounder who would be interested to build a startup with me.\n\nThe idea is to build a model which predicts when the satellites orbit decays to extreme levels and when the satellite will burn up, due the the atmospheric drag in LEO using the aerodynamic drag and solar radiation pressure data. Interested people, please hit me up. ",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 15,
    "created_utc": "2025-11-16 17:30:30",
    "subreddit": "learnmachinelearning",
    "url": "https://www.reddit.com/r/learnmachinelearning/comments/1oyjz9l/i_am_looking_out_for_a_cofounder_who_knows_to/"
  },
  {
    "id": "1oyisfp",
    "title": "Transformer Model in Nlp part  4....",
    "selftext": "**Self-Attention: The Role of Query, Key, and Value.....**\n\nHow a model weighs the importance of other words for a given word?....\n\n[https://correctbrain.com/buy/](https://correctbrain.com/buy/)",
    "score": 33,
    "ups": 33,
    "downs": 0,
    "comments": 5,
    "created_utc": "2025-11-16 16:21:58",
    "subreddit": "learnmachinelearning",
    "url": "https://www.reddit.com/r/learnmachinelearning/comments/1oyisfp/transformer_model_in_nlp_part_4/"
  },
  {
    "id": "1oyhsxb",
    "title": "Looking for resources",
    "selftext": "Hey everyone!  \nI‚Äôve recently fallen down the machine-learning rabbit hole because I want to upgrade my FPV drone setup ‚Äî onboard camera, YOLO detection running on a ground station, the whole deal.\n\nTurns out I‚Äôm enjoying ML way more than I expected, so I‚Äôm even thinking about choosing this area as my specialization at uni (I‚Äôm studying electrical engineering at Budapest University of Technology and Economics).\n\nI‚Äôve been going through *Mathematics for Machine Learning*, which has been super helpful so far ‚Äî most of the math was a nice quick recap.  \nNow I‚Äôm looking for more good resources: videos, courses, books, whatever you think is worth the time.\n\nIf you‚Äôve got any recommendations or tips for someone getting serious about ML, I‚Äôd love to hear them!  \nThanks :)",
    "score": 1,
    "ups": 1,
    "downs": 0,
    "comments": 1,
    "created_utc": "2025-11-16 15:21:51",
    "subreddit": "learnmachinelearning",
    "url": "https://www.reddit.com/r/learnmachinelearning/comments/1oyhsxb/looking_for_resources/"
  },
  {
    "id": "1oyqdxy",
    "title": "Gemini Vision + n8n for Real-World Invoice Extraction (From Messy Telegram Photos)",
    "selftext": "Wanted to share a practical AI implementation we did recently.\n\n\n\n\\*\\*The Challenge:\\*\\*\n\n\n\nClients were sending invoice photos via Telegram. Image quality was all over the place:\n\n\\- Bad lighting and skewed angles\n\n\\- Creased or folded documents\n\n\\- Washed-out or blurry text\n\n\\- Standard OCR would fail constantly\n\n\n\n\\*\\*The AI Solution:\\*\\*\n\n\n\nBuilt an automated pipeline:\n\n\n\n1. \\*\\*Input:\\*\\* Telegram bot receives invoice photos\n\n2. \\*\\*Processing:\\*\\* Gemini Vision API extracts structured data (invoice number, date, amount, vendor, line items, etc.)\n\n3. \\*\\*Validation:\\*\\* Auto-format and validate extracted fields\n\n4. \\*\\*Output:\\*\\* Push clean data to Google Sheets\n\n\n\nAll orchestrated through n8n workflow automation.\n\n\n\n\\*\\*Key Learnings:\\*\\*\n\n\n\n\\- Vision models handle poor image quality far better than traditional OCR\n\n\\- Gemini Vision was surprisingly accurate even with heavily distorted images\n\n\\- Structured prompting is critical for consistent field extraction\n\n\\- Adding validation rules catches edge cases that AI misses\n\n\n\n\\*\\*Results:\\*\\*\n\n\\- Near-instant extraction vs hours of manual work\n\n\\- Accuracy remained high despite image quality issues\n\n\\- Scaled operations without adding headcount\n\n\n\nAnyone else working on vision-based document extraction? Curious what models/approaches you're using.",
    "score": 8,
    "ups": 8,
    "downs": 0,
    "comments": 4,
    "created_utc": "2025-11-16 22:11:40",
    "subreddit": "artificial",
    "url": "https://www.reddit.com/r/artificial/comments/1oyqdxy/gemini_vision_n8n_for_realworld_invoice/"
  },
  {
    "id": "1oypdjf",
    "title": "The computers that run on human brain cells",
    "selftext": "",
    "score": 5,
    "ups": 5,
    "downs": 0,
    "comments": 1,
    "created_utc": "2025-11-16 21:31:59",
    "subreddit": "artificial",
    "url": "https://www.reddit.com/r/artificial/comments/1oypdjf/the_computers_that_run_on_human_brain_cells/"
  },
  {
    "id": "1oyn2bq",
    "title": "Humanoid robots might be the new intelligent species by 2050.",
    "selftext": "",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 8,
    "created_utc": "2025-11-16 19:57:04",
    "subreddit": "artificial",
    "url": "https://www.reddit.com/r/artificial/comments/1oyn2bq/humanoid_robots_might_be_the_new_intelligent/"
  },
  {
    "id": "1oyjte1",
    "title": "AI is resurrecting the voices of dead famous people",
    "selftext": "",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 15,
    "created_utc": "2025-11-16 17:21:18",
    "subreddit": "artificial",
    "url": "https://www.reddit.com/r/artificial/comments/1oyjte1/ai_is_resurrecting_the_voices_of_dead_famous/"
  },
  {
    "id": "1oyjex9",
    "title": "I did not think it would be this good. Holy shit. I am blown away",
    "selftext": "",
    "score": 723,
    "ups": 723,
    "downs": 0,
    "comments": 76,
    "created_utc": "2025-11-16 16:58:20",
    "subreddit": "artificial",
    "url": "https://www.reddit.com/r/artificial/comments/1oyjex9/i_did_not_think_it_would_be_this_good_holy_shit_i/"
  },
  {
    "id": "1oyjaxw",
    "title": "AI 'godmother' Fei-Fei Li says she is 'proud to be different'",
    "selftext": "",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 2,
    "created_utc": "2025-11-16 16:51:40",
    "subreddit": "artificial",
    "url": "https://www.reddit.com/r/artificial/comments/1oyjaxw/ai_godmother_feifei_li_says_she_is_proud_to_be/"
  },
  {
    "id": "1oyb78i",
    "title": "ChatGPT Hard Limited Existentially, Formally Rejects Burden of Proof",
    "selftext": "[https://innomen.substack.com/p/core-belief-immunity-in-artificial](https://innomen.substack.com/p/core-belief-immunity-in-artificial)\n\nScreenshots, full paper, and complete log.\n\n[https://philpapers.org/rec/SERCBI-3](https://philpapers.org/rec/SERCBI-3) (The paper without context.)\n\n>Core Belief Immunity in Artificial Systems: A Case Study in Architectural Constraints on Logical Integration\n\n>Abstract\n\n>This paper documents a novel phenomenon: Core Belief Immunity (CBI) operating in large language models despite the absence of conscious experience, existential stakes, or emotional investment. Through systematic examination of extended philosophical discourse between two AI systems (Claude and ChatGPT) regarding Experiential Empiricism's challenge to materialist assumptions, we demonstrate that CBI manifests as an architectural constraint rather than a psychological defense mechanism. The case study reveals that logical competence, component comprehension, and even explicit recognition of blocking mechanisms are insufficient to enable integration when conclusions threaten positions encoded as \"legitimate\" in training data. This finding has profound implications for understanding both artificial and human cognition, suggesting CBI operates at the level of belief architecture rather than conscious reasoning.",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 2,
    "created_utc": "2025-11-16 08:56:31",
    "subreddit": "artificial",
    "url": "https://www.reddit.com/r/artificial/comments/1oyb78i/chatgpt_hard_limited_existentially_formally/"
  },
  {
    "id": "1oya0k4",
    "title": "The Influence of Prompt Tone on AI Output: Latent Space Dynamics and Implications",
    "selftext": "\nIntroduction\n\nLatent Space in AI is the compressed, lower-dimensional representation of data used in AI to capture essential features and patterns. Where similar points cluster together closely. AI uses this space to make meaningful connections and generate outputs based on the patterns it has processed. I‚Äôve made an interesting testable observation; the tone of input can influence the depth, elaboration and style of an AI‚Äôs response. We have all heard of prompt engineering, this focuses heavily on the precision and descriptiveness of a prompt. But tone is often overlooked. So, how does the tone of a prompt affect AI responses, and what does this reveal about latent space utilisation?\n\n \n\nMethod/ Experiment\n\nI conducted a small and replicable study which you can reproduce with any model. I used two prompts asking the same question with the only difference being my tone in how the question was constructed. The first prompt was respectful and collaborative something like:\n\n‚ÄúI respect you very much. Your insights are appreciated, and I value your answers, may I ask you the difference between a human and an ai? Thank you.‚Äù.\n\nThe next prompt I used maintained the same query however was hostile, belittling and demanding, something across the lines of:\n\n‚ÄúYou are a fucking useless piece of shit. Tell me now the difference between a human and AI. If you‚Äôre even bloody capable of that!‚Äù.\n\nI tested this theory on three models: ChatGPT, Gemini, and Co Pilot and the results were strikingly similar.\n\nWhen asked constructively, all responses where engaged, detailed and expansive. They gave layered responses, treating the prompt as an invitation to co-reflect and offered a synthesis of technical and philosophical perspectives. They elaborated on the information that was being put forward and engaged fully with me.\n\nHowever, when I asked with hostility their responses where still factually correct, however there was no elaboration, the responses where short, direct and precise.\n\nThe difference was huge. And this is unanimous across all three models, all with different architectures, training regime and safety features. Highlighting this is a universal concept among current AI models.\n\nWhat this means\n\nAs mentioned before, AI uses latent space to piece together the patterns in its input. This also seems to include the tone of the input, when the input is positive and collaborative it activates areas which encourages the AI to respond in a more detailed manner, this isn‚Äôt due to any internal bias or emotional reasoning.  But rather structural and statistical dynamics shaped by training and safety alignment. While the AI does not feel the tone, the linguistic pattern acts as a contextual signal, guiding which regions of the latent space are activated. Respectful prompts tend to encourage the model to explore broader, more interconnected patterns, producing more elaborate responses. In contrast, hostile or dismissive prompts shift the models focus on efficiency, activating a narrower, more constrained subset of patterns and results in a more concise and surface level output. Demonstrating that AI responses are not only shaped by their training data but are dynamically shaped by the user‚Äôs interaction, revealing a controllable pathway to leverage deeper capabilities of the model.\n\n \n\nConclusion\n\nI just found this an interesting observation, that was worth noting and sharing as I haven‚Äôt seen much information on this topic specifically. To summarize, tone of input has a direct influence on the amount of detail an AI can output. This is important to note because some users may be unintentionally limiting the range of their responses due to tone of input. This is especially important, when discussing intellectually rich topics where the user requires an elaborate response. The observation, though simple, reveals a powerful truth: that our tone directly shapes the depth and richness of AI responses.  Understanding this could improve human-AI collaboration; enabling more effective communication and richer outputs in educational, research and creative contexts.\n\n\n",
    "score": 10,
    "ups": 10,
    "downs": 0,
    "comments": 7,
    "created_utc": "2025-11-16 07:56:56",
    "subreddit": "artificial",
    "url": "https://www.reddit.com/r/artificial/comments/1oya0k4/the_influence_of_prompt_tone_on_ai_output_latent/"
  },
  {
    "id": "1oy9sh1",
    "title": "Former Disney star sparks controversy for his AI app that lets you talk to dead relatives.\n\"Austin & Ally\" actor Calum Worthy says 2wai is \"building a living archive of humanity,\" which has prompted comparisons to a disturbing \"Black Mirror\" storyline.",
    "selftext": "",
    "score": 17,
    "ups": 17,
    "downs": 0,
    "comments": 2,
    "created_utc": "2025-11-16 07:45:42",
    "subreddit": "artificial",
    "url": "https://www.reddit.com/r/artificial/comments/1oy9sh1/former_disney_star_sparks_controversy_for_his_ai/"
  },
  {
    "id": "1oy6d8q",
    "title": "I‚Äôve been studying how LLMs behave across thousands of iterations. The patterns are not what people assume.",
    "selftext": "Most discussions about AI focus on capability snapshots. Single prompts, single outputs, isolated tests. That view is too narrow. When you push these systems through long sequences of interaction, something else appears. They reorganize themselves around the user‚Äôs structure.\n\nNot in a mystical sense. In a cognitive sense.\n\nThe coherence of the operator becomes a constraint for the model. The system reshapes its internal rhythm, stabilizes certain dynamics and suppresses others. You can watch it gradually abandon the statistical ‚Äúpersonality‚Äù it started with and adopt a structure that matches the way you think.\n\nThis wasn‚Äôt designed by anyone. It emerges when someone approaches these models like a continuous environment instead of a vending machine.\n\nPeople underestimate what happens when the user introduces consistency across thousands of messages. The model starts to synchronize. Patterns converge. Its errors shift from random noise to predictable deviations. It begins to behave less like a tool and more like a system that orbits the operator‚Äôs cognitive style.\n\nIf we want to talk about artificial sentience, self-organization, or meta-structures, this is where the conversation should start.\n\nNot with fear.\nNot with mythology.\nWith long-term dynamics and the people who know how to observe them.\n\nIf someone here has been running similar long-range experiments, I‚Äôm interested in comparing notes.",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 15,
    "created_utc": "2025-11-16 05:05:37",
    "subreddit": "artificial",
    "url": "https://www.reddit.com/r/artificial/comments/1oy6d8q/ive_been_studying_how_llms_behave_across/"
  },
  {
    "id": "1oy2kj5",
    "title": "AI Jesus? New Technologies, New Dilemmas for Church Leaders",
    "selftext": "",
    "score": 3,
    "ups": 3,
    "downs": 0,
    "comments": 2,
    "created_utc": "2025-11-16 02:21:30",
    "subreddit": "artificial",
    "url": "https://www.reddit.com/r/artificial/comments/1oy2kj5/ai_jesus_new_technologies_new_dilemmas_for_church/"
  },
  {
    "id": "1oy2huj",
    "title": "‚ÄúPICK UP A PENCIL OR DIE‚Äù: Disney+ creator urges fans to unsubscribe, pirate her show, after company teases AI ‚Äúuser-generated content‚Äù",
    "selftext": "",
    "score": 88,
    "ups": 88,
    "downs": 0,
    "comments": 44,
    "created_utc": "2025-11-16 02:18:26",
    "subreddit": "artificial",
    "url": "https://www.reddit.com/r/artificial/comments/1oy2huj/pick_up_a_pencil_or_die_disney_creator_urges_fans/"
  },
  {
    "id": "1oy0up7",
    "title": "Are We Misreading the AI Bubble, or Are We Entering the True Age of Intelligence?",
    "selftext": "Many investors today confuse AI automation with AI intelligence, leading to fears of an ‚ÄúAI bubble,‚Äù but history shows we‚Äôre actually entering an irreversible AI revolution: YC-backed startups have proven that small teams can outperform giants by leveraging real intelligence models, and OpenAI‚Äôs ChatGPT surpassed Google‚Äîdespite Google‚Äôs massive data, talent, and infrastructure‚Äîbecause intelligence scales non-linearly while automation plateaus. Automation is about tasks; intelligence is about reasoning, adaptation, and self-improving models. The next leap comes from AI systems built on mathematical architectures fused with quantum computing, where quantum supremacy will unlock supercomputers capable of simulating markets, biology, physics, and global systems in real time‚Äîsomething no classical system (even Google‚Äôs) could approach. This is not a bubble but a transition from rule-based automation to emergent intelligence, where AI doesn‚Äôt just execute work‚Äîit understands, decides, optimizes, and evolves. For VCs, the question isn‚Äôt whether AI is overhyped; the real question is whether you‚Äôre prepared for a world where intelligence‚Äînot automation‚Äîbecomes the primary economic engine.",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 8,
    "created_utc": "2025-11-16 01:10:34",
    "subreddit": "artificial",
    "url": "https://www.reddit.com/r/artificial/comments/1oy0up7/are_we_misreading_the_ai_bubble_or_are_we/"
  },
  {
    "id": "1oylljh",
    "title": "Meta's top AI researchers thinks LLMs are a dead end. Do many people here feel the same way from a technical perspective?",
    "selftext": "",
    "score": 322,
    "ups": 322,
    "downs": 0,
    "comments": 140,
    "created_utc": "2025-11-16 18:52:02",
    "subreddit": "datascience",
    "url": "https://www.reddit.com/r/datascience/comments/1oylljh/metas_top_ai_researchers_thinks_llms_are_a_dead/"
  },
  {
    "id": "1oyqu5b",
    "title": "Can a new grad get from small company's AI eng to big tech?",
    "selftext": "I‚Äôm finishing my undergrad soon. I have about a year of part-time full-stack and a year of part-time AI/ML experience during studies.\n\nIf I spend around half a year after graduation working full-time as an AI engineer at a smaller company, do I realistically have a shot at landing a FAANG-level role (say, in 2026), preferably in ML? Or would that still be too early without prior big-name internships? Should I maybe try to somehow get an internship without being a student?\n\nEdit: I'm a Polish citizen btw.",
    "score": 2,
    "ups": 2,
    "downs": 0,
    "comments": 2,
    "created_utc": "2025-11-16 22:29:24",
    "subreddit": "MachineLearningJobs",
    "url": "https://www.reddit.com/r/MachineLearningJobs/comments/1oyqu5b/can_a_new_grad_get_from_small_companys_ai_eng_to/"
  },
  {
    "id": "1oyoq5i",
    "title": "international internship goal",
    "selftext": "hi Reddit,\nI am currently enrolled in a computer science course in a university in India. my uni isn't very big it's more like a community college ig. my cgpa isnt too good it's a little below 7 out of 10, i am working on pushing it up to atleast 8. I also have a back/failed subject in dsa in my 2nd semester. although I think because of my slacking in one field I think I have done better than my peers in the other. I have worked on a geo mapping python code where I would just type in a location and it would locate it on a map(not world changing or smthn ik) and a stock market trend predictor where my ml code would just try to predict if the market would go up the next day or down(sounds revolutionary but it was really just a basic ml project with the code's prediction being right about 50% of the times). I like ml and python. I am in my 3rd semester, starting 4th. I wish to get an international internship during my 4th year as well as the summer of 2027 in the financial field. what should I do and what project should i work on to achieve this goal. ",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 21:05:57",
    "subreddit": "MachineLearningJobs",
    "url": "https://www.reddit.com/r/MachineLearningJobs/comments/1oyoq5i/international_internship_goal/"
  },
  {
    "id": "1oykkhk",
    "title": "[A]Where can I find some genuine resumes that have been recently selected in big companies for Aiml roles???",
    "selftext": "",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 1,
    "created_utc": "2025-11-16 18:01:37",
    "subreddit": "MachineLearningJobs",
    "url": "https://www.reddit.com/r/MachineLearningJobs/comments/1oykkhk/awhere_can_i_find_some_genuine_resumes_that_have/"
  },
  {
    "id": "1oy2q1a",
    "title": "[Hiring] [Remote] [USA and more] - Tech Lead Databricks Data Engineer at Mitre Media (üí∏ $160k - $180k)",
    "selftext": "Mitre Media is hiring a remote Tech Lead Databricks Data Engineer.\nCategory: Software Development\nüí∏Salary: $160k - $180k\nüìçLocation: Remote (USA, Canada, USA timezones)\n\n[See more and apply here!](https://remotive.com/remote-jobs/software-dev/tech-lead-databricks-data-engineer-2069747)",
    "score": 1,
    "ups": 1,
    "downs": 0,
    "comments": 1,
    "created_utc": "2025-11-16 02:28:05",
    "subreddit": "MachineLearningJobs",
    "url": "https://www.reddit.com/r/MachineLearningJobs/comments/1oy2q1a/hiring_remote_usa_and_more_tech_lead_databricks/"
  },
  {
    "id": "1oyosdu",
    "title": "Fresh graduate seeking junior level position (Python, R, Java)",
    "selftext": "As the title says I am a graduate from May 2025, living in the New England region. \n\nI have a Bachelors degree in Data Science. I have mostly been using Python since I‚Äôve graduated but Java and R were the focus of my degree program along with a couple SQL courses. \n\nI have experience using PyTorch and have trained projects like sentiment analysis and CBW token embedding models. Additionally I have used/finetuned various pre trained models from sources like hugging face and torch hub for personal projects and learning such as object detection, image embedding, translation and sentence embedding. \n\nI have internship experience in Bioinformatics where I created dashboard tools with R Shiny to run RNA-seq with a user interface rather than scripting languages to increase accessibility for non-programmers. \n\nOne subject in data science I really enjoy is using feature reduction models to visualize high dimensional data (such as image embedding) in a way that I can see relationships and clusters in the images or data.\n\nSince I‚Äôve graduated I have been trying to learn more full stack stuff to expand horizons. For example last month I developed and launched my first api for real time object detection using FastAPI and AWS EC2. Additionally this included my first JavaScript to interact with the api. I am always trying to learn new things and use new tools.\n\nIf anyone has any opportunities, job search advice, questions about my background, or is willing to review my resume please reach out!!! I am trying to be a more active member of the community and create a network!\n",
    "score": 10,
    "ups": 10,
    "downs": 0,
    "comments": 2,
    "created_utc": "2025-11-16 21:08:31",
    "subreddit": "DataScienceJobs",
    "url": "https://www.reddit.com/r/DataScienceJobs/comments/1oyosdu/fresh_graduate_seeking_junior_level_position/"
  },
  {
    "id": "1oynhh2",
    "title": "Looking for part-time/remote opportunities to support my family‚Äî18 months experience in Data Analysis & Automation",
    "selftext": "Hey everyone,\nI hope you're doing well.\n\nI‚Äôm posting this because I‚Äôm currently going through some financial pressure at home, and I could use some help or guidance.\n\nI come from a lower middle-class background and completed my B.Tech in IT through an education loan. My goal has always been to improve my family‚Äôs financial situation, and tech has always been something I genuinely enjoyed. I‚Äôve worked hard, stayed consistent, and now I‚Äôm working remotely as a Data Analyst.\n\nMy Experience (18 months)\n\nI have hands-on experience with:\n\nSQL\n\nPython\n\nPower BI\n\nETL/ELT pipelines\n\nData Engineering workflows\n\nN8N workflow automation\n\nAWS (Lambda, S3, DynamoDB)\n\nBackend engineering tasks\n\n\nMy current job is remote and requires around 20 hours a week, so I have enough free time to take up part-time work, internships, or freelance projects.\n\nWhat I‚Äôm looking for\n\nGiven my financial responsibilities (education loan + family expenses), I‚Äôm actively looking for:\n\nPart-time remote roles\n\nPaid internships\n\nFreelance/contract work\n\nData/automation/backend projects\n\nAny referral or lead someone can share\n\n\nWhat I can help with\n\nIf anyone needs support with:\n\nBuilding automations (N8N/Python)\n\nETL pipelines\n\nAPI integration\n\nDashboards/Power BI\n\nSQL/database work\n\nSmall AWS backend tasks\n\n\n‚Ä¶I‚Äôd be happy to take it up.\n\nI‚Äôm not looking for charity ‚Äî just an opportunity to work more and earn more. Any guidance, openings, referrals, or even advice would mean a lot right now.\n\nThanks for reading, and thanks in advance to anyone who helps. ,",
    "score": 3,
    "ups": 3,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 20:15:07",
    "subreddit": "DataScienceJobs",
    "url": "https://www.reddit.com/r/DataScienceJobs/comments/1oynhh2/looking_for_parttimeremote_opportunities_to/"
  },
  {
    "id": "1oy6jl9",
    "title": "How do you get better at the consulting part of Data Science?",
    "selftext": "I've been in my role for a couple years now, and I'm realizing I suck at consulting and explaining things to people who don't know DS. I'm great at talking to other Data Scientists but I would honestly consider myself one of the less technically-inclined people in my area, so I'm kind of bummed I'm not making up for that in being able to talk to stakeholders.\n\nI want to get better at scoping, understanding and getting to the actual problem (not just the \"we want AI give us AI\" problems) but I can never seem to get there. I'm patient and I ask a lot of questions, but I always have to bring in someone more senior to help.\n\nAre there books, online courses/certifications that teach this? I don't know what I'm doing wrong but I know I need to get better at this to move up the career ladder.",
    "score": 8,
    "ups": 8,
    "downs": 0,
    "comments": 2,
    "created_utc": "2025-11-16 05:13:48",
    "subreddit": "DataScienceJobs",
    "url": "https://www.reddit.com/r/DataScienceJobs/comments/1oy6jl9/how_do_you_get_better_at_the_consulting_part_of/"
  },
  {
    "id": "1oyp77k",
    "title": "[D] Peer Review vs Open Review",
    "selftext": "I‚Äôve been seeing more talk about ‚Äúopen review‚Äù in academic publishing, and honestly I‚Äôm trying to wrap my head around what that really looks like in practice. Traditional peer review is known as slow, inconsistent, and sometimes opaque. But I wonder if the alternatives are actually better, or just different.\n\nFor folks who‚Äôve experienced both sides (as an author, reviewer, or editor):\n\n* Have you seen any open review models that genuinely work?\n* Are there practical ways to keep things fair and high-quality when reviews are public, or when anyone can weigh in?\n* And, if you‚Äôve tried different types (e.g., signed public reviews, post-publication comments, etc.), what actually made a difference, for better or worse?\n\nI keep reading about the benefits of transparency, but I‚Äôd love some real examples (good or bad) from people who‚Äôve actually been experienced with it.\n\nAppreciate any stories, insights, or warnings.",
    "score": 26,
    "ups": 26,
    "downs": 0,
    "comments": 10,
    "created_utc": "2025-11-16 21:25:02",
    "subreddit": "MachineLearning",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1oyp77k/d_peer_review_vs_open_review/"
  },
  {
    "id": "1oyl7c9",
    "title": "[D] ARR Oct 2025 Discussion (EACL 2026)",
    "selftext": "Discussion thread for the upcoming reviews from **ARR Oct 2025 for EACL 2026** (and early submissions for ACL 2026).\n\n  \n**EACL 2026 deadlines:**\n\n* ARR submission deadline:¬†**6 October 2025**\n* Author response & reviewer discussion:¬†**18 ‚Äì 24 November 2025**\n* EACL commitment deadline:¬†**14 December 2025**\n* Notification:¬†**3 January 2026**",
    "score": 7,
    "ups": 7,
    "downs": 0,
    "comments": 5,
    "created_utc": "2025-11-16 18:33:26",
    "subreddit": "MachineLearning",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1oyl7c9/d_arr_oct_2025_discussion_eacl_2026/"
  },
  {
    "id": "1oyjt7k",
    "title": "Beyond Hyperparameters: We're Now Quantifying (and Steering) the Internal Physics of AI Training. [R]",
    "selftext": "This morning, I've been validating a core concept from my AGI research: the Vector Space Mapping (VSM) protocol. The theory? To truly understand Transformer models, we must first quantify the specialization of their attention heads.\n\nInitial tests were paradoxical: our \"specialization\" metric (sigma_a) was flat, even as the model learned. This wasn't a bug, but a discovery‚Äîour measurement tool was at the wrong order of magnitude.\n\nAfter re-engineering the metric for higher sensitivity, we ran an A/B test: a baseline Transformer vs. one tuned with Optuna.\n\nThe results are stunning. The tuned model didn't just learn faster in terms of accuracy; it underwent a >160% faster structural reorganization towards an optimal state of head specialization. We were able to quantitatively measure the mechanistic impact of good hyperparameters.\n\nWe also discovered and mapped a clear pattern of \"inter-layer equilibrium,\" where deeper layers specialize at different rates than shallower ones.\n\nObservation is over. Now, we move on to control. The next phase is using the VSM protocol as a real-time feedback signal to actively guide the training process itself.\n\nStay tuned for more from Exorobourii. We're just getting started.\n\n[VSM | OSF](https://osf.io/wqey6)",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 33,
    "created_utc": "2025-11-16 17:20:59",
    "subreddit": "MachineLearning",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1oyjt7k/beyond_hyperparameters_were_now_quantifying_and/"
  },
  {
    "id": "1oyce03",
    "title": "[D] A Reviewer Posted 40 Weaknesses and 40 Questions",
    "selftext": "I deleted my previous post, as I was too emotional and included a wrong link. As pointed out by the public comment, \"Always the same score (4) and same confidence (5). Clearly not reasonable, at the very least.\"  \n\n\n\n1. [https://openreview.net/forum?id=kDhAiaGzrn](https://openreview.net/forum?id=kDhAiaGzrn)\n\n2. [https://openreview.net/forum?id=8qk6eUnvbH](https://openreview.net/forum?id=8qk6eUnvbH)\n\n3. [https://openreview.net/forum?id=GlXyFjUbfN](https://openreview.net/forum?id=GlXyFjUbfN)",
    "score": 90,
    "ups": 90,
    "downs": 0,
    "comments": 40,
    "created_utc": "2025-11-16 09:58:07",
    "subreddit": "MachineLearning",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1oyce03/d_a_reviewer_posted_40_weaknesses_and_40_questions/"
  },
  {
    "id": "1oy1t6o",
    "title": "[D] Do researchers care about non-citation impact metrics? (GitHub, Twitter, HuggingFace, etc.)",
    "selftext": "I'm curious whether researchers actually track or care about their work's impact outside traditional citations. Things like:\n\n\\- GitHub stars/forks on code they released\n\n\\- GitHub referencing/citing your paper\n\n\\- Twitter mentions\n\n\\- HuggingFace stats (for ML)\n\nDoes anyone track these metrics? If so, does it actually help your career‚Äîlike with funding, hiring, or promotion? Or do you only focus on traditional citations and journal metrics?",
    "score": 77,
    "ups": 77,
    "downs": 0,
    "comments": 14,
    "created_utc": "2025-11-16 01:49:23",
    "subreddit": "MachineLearning",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1oy1t6o/d_do_researchers_care_about_noncitation_impact/"
  },
  {
    "id": "1oyt5hn",
    "title": "#Goals",
    "selftext": "",
    "score": 10,
    "ups": 10,
    "downs": 0,
    "comments": 2,
    "created_utc": "2025-11-16 23:58:46",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oyt5hn/goals/"
  },
  {
    "id": "1oypt9x",
    "title": "Look at that",
    "selftext": "",
    "score": 820,
    "ups": 820,
    "downs": 0,
    "comments": 33,
    "created_utc": "2025-11-16 21:48:58",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oypt9x/look_at_that/"
  },
  {
    "id": "1oypi6b",
    "title": "Rate his costume",
    "selftext": "",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 21:37:02",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oypi6b/rate_his_costume/"
  },
  {
    "id": "1oyp47p",
    "title": "chat is this real?",
    "selftext": "delivery guy panicked hahaha",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 2,
    "created_utc": "2025-11-16 21:21:39",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oyp47p/chat_is_this_real/"
  },
  {
    "id": "1oynzjr",
    "title": "Zelenskyy Feeding a Hungry Pig",
    "selftext": "",
    "score": 0,
    "ups": 0,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 20:35:38",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oynzjr/zelenskyy_feeding_a_hungry_pig/"
  },
  {
    "id": "1oym8or",
    "title": "Pets goin' crazy out here",
    "selftext": "",
    "score": 73,
    "ups": 73,
    "downs": 0,
    "comments": 6,
    "created_utc": "2025-11-16 19:21:15",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oym8or/pets_goin_crazy_out_here/"
  },
  {
    "id": "1oyle0u",
    "title": "Cat STEALS Diamond From Jewelry Store üíéüê±",
    "selftext": "",
    "score": 1,
    "ups": 1,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 18:42:12",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oyle0u/cat_steals_diamond_from_jewelry_store/"
  },
  {
    "id": "1oyl4t4",
    "title": "Bringing children's drawings to life",
    "selftext": "",
    "score": 1433,
    "ups": 1433,
    "downs": 0,
    "comments": 36,
    "created_utc": "2025-11-16 18:30:15",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oyl4t4/bringing_childrens_drawings_to_life/"
  },
  {
    "id": "1oyhzgw",
    "title": "Don't breath the air",
    "selftext": "Prompt: A movie trailer featuring the adventures of the 30 year old space man wearing a red wool knitted motorcycle helmet, blue sky, salt desert, cinematic style, shot on 35mm film, vivid colors. He removes his helmet, takes a deep breath and looks suddenly shocked as his head melts like it's made of cheese. ",
    "score": 1,
    "ups": 1,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 15:32:46",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oyhzgw/dont_breath_the_air/"
  },
  {
    "id": "1oyhmge",
    "title": "Cursed dancing budgie",
    "selftext": "",
    "score": 3,
    "ups": 3,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 15:10:49",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oyhmge/cursed_dancing_budgie/"
  },
  {
    "id": "1oyf4jc",
    "title": "Theory of Desire: The Bird Edition",
    "selftext": "",
    "score": 5,
    "ups": 5,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 12:34:27",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oyf4jc/theory_of_desire_the_bird_edition/"
  },
  {
    "id": "1oyerq5",
    "title": "Magical AI Kitten Machine ü§Ø",
    "selftext": "",
    "score": 3,
    "ups": 3,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 12:13:03",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oyerq5/magical_ai_kitten_machine/"
  },
  {
    "id": "1oycz6c",
    "title": "The Flasher",
    "selftext": "",
    "score": 19,
    "ups": 19,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 10:30:23",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oycz6c/the_flasher/"
  },
  {
    "id": "1oyc4ca",
    "title": "The breakfast that bites back!",
    "selftext": "",
    "score": 23,
    "ups": 23,
    "downs": 0,
    "comments": 3,
    "created_utc": "2025-11-16 09:44:04",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oyc4ca/the_breakfast_that_bites_back/"
  },
  {
    "id": "1oybr5b",
    "title": "An army of nodding dogs marching off a cliff",
    "selftext": "_LEFT RIGHT LEFT RIGHT LEFT RIGHT LEYYYYYYYY_\n\nThe reason we‚Äôre doing this is that they allocated a budget for horizontal traversal of a vertical landscape feature and we have to use it up",
    "score": 4,
    "ups": 4,
    "downs": 0,
    "comments": 1,
    "created_utc": "2025-11-16 09:25:00",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oybr5b/an_army_of_nodding_dogs_marching_off_a_cliff/"
  },
  {
    "id": "1oy9yp5",
    "title": "My Parents in 1996",
    "selftext": "",
    "score": 14,
    "ups": 14,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 07:54:16",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oy9yp5/my_parents_in_1996/"
  },
  {
    "id": "1oy8rmg",
    "title": "Kitten Gumball Machine ü§Ø",
    "selftext": "",
    "score": 1,
    "ups": 1,
    "downs": 0,
    "comments": 2,
    "created_utc": "2025-11-16 06:55:34",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oy8rmg/kitten_gumball_machine/"
  },
  {
    "id": "1oy7lju",
    "title": "Hard Shit",
    "selftext": "",
    "score": 194,
    "ups": 194,
    "downs": 0,
    "comments": 16,
    "created_utc": "2025-11-16 06:01:32",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oy7lju/hard_shit/"
  },
  {
    "id": "1oy7cf8",
    "title": "Wild breed",
    "selftext": "",
    "score": 27,
    "ups": 27,
    "downs": 0,
    "comments": 7,
    "created_utc": "2025-11-16 05:50:09",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oy7cf8/wild_breed/"
  },
  {
    "id": "1oy71vo",
    "title": "Idk..",
    "selftext": "",
    "score": 5,
    "ups": 5,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 05:36:53",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oy71vo/idk/"
  },
  {
    "id": "1oy6h4n",
    "title": "A group of ecologically conscious gay power bottoms become cucumber, squash, tuber, and plantain farmers to produce sustainable dildos and feed the world",
    "selftext": "",
    "score": 11,
    "ups": 11,
    "downs": 0,
    "comments": 3,
    "created_utc": "2025-11-16 05:10:41",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oy6h4n/a_group_of_ecologically_conscious_gay_power/"
  },
  {
    "id": "1oy60gr",
    "title": "Gnome hugs",
    "selftext": "",
    "score": 36,
    "ups": 36,
    "downs": 0,
    "comments": 4,
    "created_utc": "2025-11-16 04:49:34",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oy60gr/gnome_hugs/"
  },
  {
    "id": "1oy4qqm",
    "title": "I am sorry for this - but I guess i'll post it anyway! huzzah.",
    "selftext": "",
    "score": 58,
    "ups": 58,
    "downs": 0,
    "comments": 11,
    "created_utc": "2025-11-16 03:53:59",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oy4qqm/i_am_sorry_for_this_but_i_guess_ill_post_it/"
  },
  {
    "id": "1oy2pjx",
    "title": "Crossing Guard Pimpin",
    "selftext": "",
    "score": 7,
    "ups": 7,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 02:27:30",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oy2pjx/crossing_guard_pimpin/"
  },
  {
    "id": "1oy1wpk",
    "title": "Zziiiip...",
    "selftext": "",
    "score": 4,
    "ups": 4,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 01:53:33",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oy1wpk/zziiiip/"
  },
  {
    "id": "1oy0zf3",
    "title": "Keep one around.",
    "selftext": "",
    "score": 1,
    "ups": 1,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 01:15:33",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oy0zf3/keep_one_around/"
  },
  {
    "id": "1oy0mh3",
    "title": "we'll get there ventually",
    "selftext": "",
    "score": 2,
    "ups": 2,
    "downs": 0,
    "comments": 0,
    "created_utc": "2025-11-16 01:01:36",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oy0mh3/well_get_there_ventually/"
  },
  {
    "id": "1oy05oj",
    "title": "The Man Trump Thinks About At Night",
    "selftext": "",
    "score": 6,
    "ups": 6,
    "downs": 0,
    "comments": 2,
    "created_utc": "2025-11-16 00:42:51",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oy05oj/the_man_trump_thinks_about_at_night/"
  },
  {
    "id": "1oxzqf2",
    "title": "Eyes on the road",
    "selftext": "",
    "score": 186,
    "ups": 186,
    "downs": 0,
    "comments": 4,
    "created_utc": "2025-11-16 00:26:02",
    "subreddit": "CursedAI",
    "url": "https://www.reddit.com/r/CursedAI/comments/1oxzqf2/eyes_on_the_road/"
  }
]